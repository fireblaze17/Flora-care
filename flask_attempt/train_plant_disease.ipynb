{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70295 files belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "#training_image_preprocessing\n",
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    \n",
    "    \n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17572 files belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "#validation_image_preprocessing\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    \n",
    "    \n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries for building model\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building convolution layer - detects features creates 'copies' of the image with specific features in this case 32 diffrent within a 3x3 matrix\n",
    "model.add(Conv2D(filters = 32,kernel_size = 3, padding = 'same', activation = 'relu', input_shape = [128,128,3]))\n",
    "model.add(Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\n",
    "#max pooling layer - featrue extraction. selects the maximum value within the region instead of the whole region to reduce dimesions\n",
    "model.add(MaxPool2D(pool_size= 2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building convolution layer - detects features creates 'copies' of the image with specific features in this case 32 diffrent within a 3x3 matrix\n",
    "model.add(Conv2D(filters = 64,kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 64,kernel_size = 3, activation = 'relu'))\n",
    "#max pooling layer - featrue extraction. selects the maximum value within the region instead of the whole region to reduce dimesions\n",
    "model.add(MaxPool2D(pool_size= 2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building convolution layer - detects features creates 'copies' of the image with specific features in this case 32 diffrent within a 3x3 matrix\n",
    "model.add(Conv2D(filters = 128,kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 128,kernel_size = 3, activation = 'relu'))\n",
    "#max pooling layer - featrue extraction. selects the maximum value within the region instead of the whole region to reduce dimesions\n",
    "model.add(MaxPool2D(pool_size= 2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building convolution layer - detects features creates 'copies' of the image with specific features in this case 32 diffrent within a 3x3 matrix\n",
    "model.add(Conv2D(filters = 256,kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 256,kernel_size = 3, activation = 'relu'))\n",
    "#max pooling layer - featrue extraction. selects the maximum value within the region instead of the whole region to reduce dimesions\n",
    "model.add(MaxPool2D(pool_size= 2, strides=2)) \n",
    "# this combination works best 4 layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building convolution layer - detects features creates 'copies' of the image with specific features in this case 32 diffrent within a 3x3 matrix\n",
    "model.add(Conv2D(filters = 512,kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 512,kernel_size = 3, activation = 'relu'))\n",
    "#max pooling layer - featrue extraction. selects the maximum value within the region instead of the whole region to reduce dimesions\n",
    "model.add(MaxPool2D(pool_size= 2, strides=2)) \n",
    "# this combination works best 5 layers tried with 4 wasnt good it was underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten()) #flatten layer, converts the extracted features from a 2D array to a 1D array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 1500, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 38, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling model\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy']) #changed learning rate from0.001 to 0.0001 to stop overshooting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 126, 126, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 63, 63, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 63, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 61, 61, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 30, 30, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 30, 30, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 28, 28, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 14, 14, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 14, 14, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 6, 6, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 2, 2, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1500)              3073500   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1500)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 38)                57038     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,842,762\n",
      "Trainable params: 7,842,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2197/2197 [==============================] - 117s 49ms/step - loss: 1.3882 - accuracy: 0.5912 - val_loss: 0.4337 - val_accuracy: 0.8629\n",
      "Epoch 2/10\n",
      "2197/2197 [==============================] - 106s 48ms/step - loss: 0.4512 - accuracy: 0.8558 - val_loss: 0.2691 - val_accuracy: 0.9137\n",
      "Epoch 3/10\n",
      "2197/2197 [==============================] - 107s 49ms/step - loss: 0.2626 - accuracy: 0.9148 - val_loss: 0.1983 - val_accuracy: 0.9380\n",
      "Epoch 4/10\n",
      "2197/2197 [==============================] - 106s 48ms/step - loss: 0.1844 - accuracy: 0.9399 - val_loss: 0.1528 - val_accuracy: 0.9511\n",
      "Epoch 5/10\n",
      "2197/2197 [==============================] - 106s 48ms/step - loss: 0.1354 - accuracy: 0.9549 - val_loss: 0.1537 - val_accuracy: 0.9508\n",
      "Epoch 6/10\n",
      "2197/2197 [==============================] - 106s 48ms/step - loss: 0.1036 - accuracy: 0.9660 - val_loss: 0.1152 - val_accuracy: 0.9632\n",
      "Epoch 7/10\n",
      "2197/2197 [==============================] - 106s 48ms/step - loss: 0.0838 - accuracy: 0.9721 - val_loss: 0.1201 - val_accuracy: 0.9631\n",
      "Epoch 8/10\n",
      "2197/2197 [==============================] - 106s 48ms/step - loss: 0.0720 - accuracy: 0.9772 - val_loss: 0.1008 - val_accuracy: 0.9685\n",
      "Epoch 9/10\n",
      "2197/2197 [==============================] - 106s 48ms/step - loss: 0.0603 - accuracy: 0.9809 - val_loss: 0.1049 - val_accuracy: 0.9706\n",
      "Epoch 10/10\n",
      "2197/2197 [==============================] - 106s 48ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 0.1614 - val_accuracy: 0.9538\n"
     ]
    }
   ],
   "source": [
    "#model training\n",
    "training_history = model.fit(x=training_set,validation_data = validation_set,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2197/2197 [==============================] - 34s 15ms/step - loss: 0.0613 - accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "## evaluation on training set\n",
    "train_loss, train_acc  = model.evaluate(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06134776771068573 0.9802688956260681\n"
     ]
    }
   ],
   "source": [
    "print(train_loss, train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550/550 [==============================] - 9s 15ms/step - loss: 0.1614 - accuracy: 0.9538\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc  = model.evaluate(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16141073405742645 0.9538470506668091\n"
     ]
    }
   ],
   "source": [
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model\n",
    "model.save(\"trained_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, verbose=1)\n",
    "\n",
    "history = model.fit(train, epochs=100, validation_data=valid_dataset, callbacks=[early_stopping], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"trained_model_v2.h5\")\n",
    "print(\"Model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weights_for_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
